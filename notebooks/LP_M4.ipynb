{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3196b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "import torch_geometric.transforms as T\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.nn import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457c8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"/home/schoenstein/these/gnn_postbiblio/graph/graph_light.gml\")\n",
    "data = from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836aa2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 664450], num_nodes=116979, edge_label=[664450], edge_label_index=[2, 664450])\n",
      "Data(edge_index=[2, 664450], num_nodes=116979, edge_label=[83056], edge_label_index=[2, 83056])\n",
      "Data(edge_index=[2, 747506], num_nodes=116979, edge_label=[83056], edge_label_index=[2, 83056])\n"
     ]
    }
   ],
   "source": [
    "train = \"random\"\n",
    "\n",
    "if train == \"random\":\n",
    "    transform = T.RandomLinkSplit(\n",
    "        num_val = 0.1,  \n",
    "        num_test = 0.1,  \n",
    "        disjoint_train_ratio = 0,  \n",
    "        neg_sampling_ratio = 1,\n",
    "        is_undirected = True\n",
    "    )\n",
    "    train_data, val_data, test_data = transform(data)\n",
    "    print(train_data)\n",
    "    print(val_data)\n",
    "    print(test_data)\n",
    "\n",
    "elif train == \"double split\":\n",
    "    cc = list(nx.connected_components(G))\n",
    "    neg_inside = 0\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    test_list = []\n",
    "    for c in cc:\n",
    "        G2 = G.subgraph(c).copy()\n",
    "        data2 = from_networkx(G2)\n",
    "        transform = T.RandomLinkSplit(\n",
    "                num_val = 0.1,  \n",
    "                num_test = 0.1,  \n",
    "                disjoint_train_ratio = 0,  \n",
    "                neg_sampling_ratio = 1.5,\n",
    "                is_undirected = True\n",
    "            )\n",
    "        train_data2, val_data2, test_data2 = transform(data2)\n",
    "        neg_inside = neg_inside + len(train_data2.edge_label)\n",
    "        train_list.append(train_data2)\n",
    "        val_list.append(val_data2)\n",
    "        test_list.append(test_data2)\n",
    "    ratio_neg_inside = neg_inside/(len(list(G.edges()))*2)\n",
    "    print(ratio_neg_inside)\n",
    "    transform = T.RandomLinkSplit(\n",
    "            num_val = 0.1,  \n",
    "            num_test = 0.1,  \n",
    "            disjoint_train_ratio = 0,  \n",
    "            neg_sampling_ratio = 1 - ratio_neg_inside,\n",
    "            is_undirected = True\n",
    "        )\n",
    "    train_data3, val_data3, test_data3 = transform(data)\n",
    "\n",
    "    #pos_train = torch.cat([d.edge_label_index[:, d.edge_label==1] \n",
    "                             #for d in train_list], dim=1)\n",
    "    pos_train = train_data3.edge_label_index[:, train_data3.edge_label == 1]\n",
    "    #pos_val = torch.cat([d.edge_label_index[:, d.edge_label==1] \n",
    "                           #for d in val_list], dim=1)\n",
    "    pos_val = val_data3.edge_label_index[:, val_data3.edge_label == 1]\n",
    "    #pos_test = torch.cat([d.edge_label_index[:, d.edge_label==1] \n",
    "                            #for d in test_list], dim=1)\n",
    "    pos_test = test_data3.edge_label_index[:, test_data3.edge_label == 1]\n",
    "    neg_train1 = torch.cat([d.edge_label_index[:, d.edge_label==0] \n",
    "                             for d in train_list], dim=1)\n",
    "    neg_val1 = torch.cat([d.edge_label_index[:, d.edge_label==0] \n",
    "                           for d in val_list], dim=1)\n",
    "    neg_test1 = torch.cat([d.edge_label_index[:, d.edge_label==0] \n",
    "                            for d in test_list], dim=1)\n",
    "    neg_train2 = train_data3.edge_label_index[:, train_data3.edge_label==0]             \n",
    "    neg_val2 = val_data3.edge_label_index[:, val_data3.edge_label==0] \n",
    "    neg_test2 = test_data3.edge_label_index[:, test_data3.edge_label==0]\n",
    "    neg_train = torch.cat([neg_train1, neg_train2], dim=1)\n",
    "    neg_val = torch.cat([neg_val1, neg_val2], dim=1)\n",
    "    neg_test = torch.cat([neg_test1, neg_test2], dim=1)\n",
    "    train_data = Data(\n",
    "        edge_index=train_data3.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        edge_label_index=torch.cat([pos_train, neg_train], dim=1),\n",
    "        edge_label=torch.cat([\n",
    "            torch.ones(pos_train.size(1), dtype=torch.long),\n",
    "            torch.zeros(neg_train.size(1), dtype=torch.long)\n",
    "        ])\n",
    "    )\n",
    "    val_data = Data(\n",
    "        edge_index=val_data3.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        edge_label_index=torch.cat([pos_val, neg_val], dim=1),\n",
    "        edge_label=torch.cat([\n",
    "            torch.ones(pos_val.size(1), dtype=torch.long),\n",
    "            torch.zeros(neg_val.size(1), dtype=torch.long)\n",
    "        ])\n",
    "    )\n",
    "    test_data = Data(\n",
    "        edge_index=test_data3.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        edge_label_index=torch.cat([pos_test, neg_test], dim=1),\n",
    "        edge_label=torch.cat([\n",
    "            torch.ones(pos_test.size(1), dtype=torch.long),\n",
    "            torch.zeros(neg_test.size(1), dtype=torch.long)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    print(train_data)\n",
    "    print(val_data)\n",
    "    print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd890ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.x = torch.ones((train_data.num_nodes, 1))\n",
    "val_data.x = train_data.x.clone()\n",
    "test_data.x = train_data.x.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4f3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n2v = Node2Vec(\n",
    "    edge_index = train_data.edge_index,\n",
    "    embedding_dim = 64,\n",
    "    walk_length = 20,\n",
    "    context_size = 10,\n",
    "    walks_per_node = 10,\n",
    "    p = 1.0,\n",
    "    q = 1.0,\n",
    "    num_negative_samples = 1,\n",
    "    sparse=True\n",
    ")\n",
    "optimizer = torch.optim.SparseAdam(list(model_n2v.parameters()), lr=0.01)\n",
    "n2v_loader = model_n2v.loader(batch_size = 128, shuffle =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3fe1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 2.8980\n",
      "Epoch 002 | Loss: 1.2316\n",
      "Epoch 003 | Loss: 0.9485\n",
      "Epoch 004 | Loss: 0.8530\n",
      "Epoch 005 | Loss: 0.8115\n",
      "Epoch 006 | Loss: 0.7893\n",
      "Epoch 007 | Loss: 0.7761\n",
      "Epoch 008 | Loss: 0.7677\n",
      "Epoch 009 | Loss: 0.7620\n"
     ]
    }
   ],
   "source": [
    "def train_epoch():\n",
    "    model_n2v.train()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for pos, neg in n2v_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model_n2v.loss(pos, neg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss = total_loss + loss.item()\n",
    "        count = count + 1\n",
    "    return total_loss / count\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    loss = train_epoch()\n",
    "    print(f\"Epoch {epoch:03d} | Loss: {loss:.4f}\")\n",
    "\n",
    "model_n2v.eval()\n",
    "z = model_n2v() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde53c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_label_index):\n",
    "        edge_emb_src = x[edge_label_index[0]]\n",
    "        edge_emb_dst = x[edge_label_index[1]]\n",
    "        edge_emb = torch.cat([edge_emb_src, edge_emb_dst], dim=-1)\n",
    "        return self.mlp(edge_emb).view(-1)\n",
    "\n",
    "predictor = Predictor(hidden_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08b5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Loss: 0.6925, Val Loss : 0.6844, Val AUC: 0.6570, Val AP: 0.6637\n",
      "Epoch 002, Loss: 0.6836, Val Loss : 0.6757, Val AUC: 0.7378, Val AP: 0.7447\n",
      "Epoch 003, Loss: 0.6743, Val Loss : 0.6660, Val AUC: 0.7829, Val AP: 0.7875\n",
      "Epoch 004, Loss: 0.6640, Val Loss : 0.6556, Val AUC: 0.8096, Val AP: 0.8117\n",
      "Epoch 005, Loss: 0.6529, Val Loss : 0.6447, Val AUC: 0.8285, Val AP: 0.8279\n",
      "Epoch 006, Loss: 0.6413, Val Loss : 0.6335, Val AUC: 0.8448, Val AP: 0.8414\n",
      "Epoch 007, Loss: 0.6294, Val Loss : 0.6220, Val AUC: 0.8609, Val AP: 0.8553\n",
      "Epoch 008, Loss: 0.6172, Val Loss : 0.6100, Val AUC: 0.8777, Val AP: 0.8705\n",
      "Epoch 009, Loss: 0.6045, Val Loss : 0.5973, Val AUC: 0.8952, Val AP: 0.8874\n",
      "Epoch 010, Loss: 0.5910, Val Loss : 0.5838, Val AUC: 0.9128, Val AP: 0.9053\n",
      "Epoch 011, Loss: 0.5766, Val Loss : 0.5694, Val AUC: 0.9292, Val AP: 0.9229\n",
      "Epoch 012, Loss: 0.5612, Val Loss : 0.5541, Val AUC: 0.9431, Val AP: 0.9384\n",
      "Epoch 013, Loss: 0.5448, Val Loss : 0.5381, Val AUC: 0.9539, Val AP: 0.9508\n",
      "Epoch 014, Loss: 0.5277, Val Loss : 0.5214, Val AUC: 0.9616, Val AP: 0.9602\n",
      "Epoch 015, Loss: 0.5098, Val Loss : 0.5042, Val AUC: 0.9669, Val AP: 0.9670\n",
      "Epoch 016, Loss: 0.4913, Val Loss : 0.4864, Val AUC: 0.9706, Val AP: 0.9718\n",
      "Epoch 017, Loss: 0.4722, Val Loss : 0.4681, Val AUC: 0.9732, Val AP: 0.9753\n",
      "Epoch 018, Loss: 0.4526, Val Loss : 0.4495, Val AUC: 0.9752, Val AP: 0.9779\n",
      "Epoch 019, Loss: 0.4328, Val Loss : 0.4307, Val AUC: 0.9767, Val AP: 0.9800\n",
      "Epoch 020, Loss: 0.4128, Val Loss : 0.4119, Val AUC: 0.9779, Val AP: 0.9817\n",
      "Epoch 021, Loss: 0.3927, Val Loss : 0.3932, Val AUC: 0.9789, Val AP: 0.9830\n",
      "Epoch 022, Loss: 0.3727, Val Loss : 0.3748, Val AUC: 0.9798, Val AP: 0.9842\n",
      "Epoch 023, Loss: 0.3529, Val Loss : 0.3568, Val AUC: 0.9805, Val AP: 0.9852\n",
      "Epoch 024, Loss: 0.3334, Val Loss : 0.3392, Val AUC: 0.9812, Val AP: 0.9860\n",
      "Epoch 025, Loss: 0.3143, Val Loss : 0.3222, Val AUC: 0.9817, Val AP: 0.9867\n",
      "Epoch 026, Loss: 0.2958, Val Loss : 0.3057, Val AUC: 0.9821, Val AP: 0.9873\n",
      "Epoch 027, Loss: 0.2779, Val Loss : 0.2897, Val AUC: 0.9825, Val AP: 0.9877\n",
      "Epoch 028, Loss: 0.2607, Val Loss : 0.2745, Val AUC: 0.9829, Val AP: 0.9881\n",
      "Epoch 029, Loss: 0.2442, Val Loss : 0.2601, Val AUC: 0.9831, Val AP: 0.9885\n",
      "Epoch 030, Loss: 0.2286, Val Loss : 0.2467, Val AUC: 0.9834, Val AP: 0.9888\n",
      "Epoch 031, Loss: 0.2139, Val Loss : 0.2343, Val AUC: 0.9836, Val AP: 0.9890\n",
      "Epoch 032, Loss: 0.2000, Val Loss : 0.2227, Val AUC: 0.9837, Val AP: 0.9892\n",
      "Epoch 033, Loss: 0.1870, Val Loss : 0.2121, Val AUC: 0.9839, Val AP: 0.9893\n",
      "Epoch 034, Loss: 0.1749, Val Loss : 0.2022, Val AUC: 0.9840, Val AP: 0.9895\n",
      "Epoch 035, Loss: 0.1636, Val Loss : 0.1930, Val AUC: 0.9841, Val AP: 0.9896\n",
      "Epoch 036, Loss: 0.1532, Val Loss : 0.1846, Val AUC: 0.9842, Val AP: 0.9897\n",
      "Epoch 037, Loss: 0.1436, Val Loss : 0.1770, Val AUC: 0.9843, Val AP: 0.9897\n",
      "Epoch 038, Loss: 0.1347, Val Loss : 0.1702, Val AUC: 0.9843, Val AP: 0.9898\n",
      "Epoch 039, Loss: 0.1266, Val Loss : 0.1641, Val AUC: 0.9844, Val AP: 0.9899\n",
      "Epoch 040, Loss: 0.1192, Val Loss : 0.1587, Val AUC: 0.9844, Val AP: 0.9899\n",
      "Epoch 041, Loss: 0.1124, Val Loss : 0.1539, Val AUC: 0.9845, Val AP: 0.9900\n",
      "Epoch 042, Loss: 0.1061, Val Loss : 0.1495, Val AUC: 0.9845, Val AP: 0.9900\n",
      "Epoch 043, Loss: 0.1004, Val Loss : 0.1455, Val AUC: 0.9846, Val AP: 0.9901\n",
      "Epoch 044, Loss: 0.0952, Val Loss : 0.1419, Val AUC: 0.9846, Val AP: 0.9901\n",
      "Epoch 045, Loss: 0.0905, Val Loss : 0.1387, Val AUC: 0.9846, Val AP: 0.9901\n",
      "Epoch 046, Loss: 0.0861, Val Loss : 0.1359, Val AUC: 0.9846, Val AP: 0.9902\n",
      "Epoch 047, Loss: 0.0821, Val Loss : 0.1335, Val AUC: 0.9847, Val AP: 0.9902\n",
      "Epoch 048, Loss: 0.0785, Val Loss : 0.1315, Val AUC: 0.9847, Val AP: 0.9902\n",
      "Epoch 049, Loss: 0.0751, Val Loss : 0.1297, Val AUC: 0.9847, Val AP: 0.9902\n"
     ]
    }
   ],
   "source": [
    "optimizer_mlp = torch.optim.Adam(predictor.parameters(), lr=0.01)\n",
    "\n",
    "def train_epoch2():\n",
    "    predictor.train()\n",
    "    optimizer_mlp.zero_grad()\n",
    "    pred = predictor(z, train_data.edge_label_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(pred, train_data.edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer_mlp.step()\n",
    "    return loss\n",
    "\n",
    "def evaluate():\n",
    "    predictor.eval()\n",
    "    y_pred = predictor(z, val_data.edge_label_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(y_pred, val_data.edge_label.float()).item()\n",
    "    auc = roc_auc_score(val_data.edge_label.numpy(), y_pred.detach().numpy())\n",
    "    ap = average_precision_score(val_data.edge_label.numpy(), y_pred.detach().numpy())\n",
    "    return loss, auc, ap\n",
    "\n",
    "best_val_auc = 0\n",
    "limit = 6\n",
    "count = 0\n",
    "val_aps = []\n",
    "val_aucs = []\n",
    "for epoch in range(1, 50):\n",
    "    loss = train_epoch2()\n",
    "    val_loss, val_auc, val_ap = evaluate()\n",
    "    print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Val Loss : {val_loss:.4f}, Val AUC: {val_auc:.4f}, Val AP: {val_ap:.4f}\")\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        count = 0\n",
    "    else:\n",
    "        count =  count + 1\n",
    "        if count >= limit:\n",
    "            print(\"Early stop\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
