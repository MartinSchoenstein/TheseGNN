{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea9a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "import torch_geometric.transforms as T\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699f08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"/home/schoenstein/these/gnn_postbiblio/graph/graph_light.gml\")\n",
    "data = from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8f626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 664450], num_nodes=116979, edge_label=[664450], edge_label_index=[2, 664450])\n",
      "Data(edge_index=[2, 664450], num_nodes=116979, edge_label=[83056], edge_label_index=[2, 83056])\n",
      "Data(edge_index=[2, 747506], num_nodes=116979, edge_label=[83056], edge_label_index=[2, 83056])\n"
     ]
    }
   ],
   "source": [
    "train = \"random\"\n",
    "\n",
    "if train == \"random\":\n",
    "    transform = T.RandomLinkSplit(\n",
    "        num_val = 0.1,  \n",
    "        num_test = 0.1,  \n",
    "        disjoint_train_ratio = 0,  \n",
    "        neg_sampling_ratio = 1,\n",
    "        is_undirected = True\n",
    "    )\n",
    "    train_data, val_data, test_data = transform(data)\n",
    "    print(train_data)\n",
    "    print(val_data)\n",
    "    print(test_data)\n",
    "\n",
    "elif train == \"double split\":\n",
    "    cc = list(nx.connected_components(G))\n",
    "    neg_inside = 0\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    test_list = []\n",
    "    for c in cc:\n",
    "        G2 = G.subgraph(c).copy()\n",
    "        data2 = from_networkx(G2)\n",
    "        transform = T.RandomLinkSplit(\n",
    "                num_val = 0.1,  \n",
    "                num_test = 0.1,  \n",
    "                disjoint_train_ratio = 0,  \n",
    "                neg_sampling_ratio = 1.5,\n",
    "                is_undirected = True\n",
    "            )\n",
    "        train_data2, val_data2, test_data2 = transform(data2)\n",
    "        neg_inside = neg_inside + len(train_data2.edge_label)\n",
    "        train_list.append(train_data2)\n",
    "        val_list.append(val_data2)\n",
    "        test_list.append(test_data2)\n",
    "    ratio_neg_inside = neg_inside/(len(list(G.edges()))*2)\n",
    "    print(ratio_neg_inside)\n",
    "    transform = T.RandomLinkSplit(\n",
    "            num_val = 0.1,  \n",
    "            num_test = 0.1,  \n",
    "            disjoint_train_ratio = 0,  \n",
    "            neg_sampling_ratio = 1 - ratio_neg_inside,\n",
    "            is_undirected = True\n",
    "        )\n",
    "    train_data3, val_data3, test_data3 = transform(data)\n",
    "\n",
    "    #pos_train = torch.cat([d.edge_label_index[:, d.edge_label==1] \n",
    "                             #for d in train_list], dim=1)\n",
    "    pos_train = train_data3.edge_label_index[:, train_data3.edge_label == 1]\n",
    "    #pos_val = torch.cat([d.edge_label_index[:, d.edge_label==1] \n",
    "                           #for d in val_list], dim=1)\n",
    "    pos_val = val_data3.edge_label_index[:, val_data3.edge_label == 1]\n",
    "    #pos_test = torch.cat([d.edge_label_index[:, d.edge_label==1] \n",
    "                            #for d in test_list], dim=1)\n",
    "    pos_test = test_data3.edge_label_index[:, test_data3.edge_label == 1]\n",
    "    neg_train1 = torch.cat([d.edge_label_index[:, d.edge_label==0] \n",
    "                             for d in train_list], dim=1)\n",
    "    neg_val1 = torch.cat([d.edge_label_index[:, d.edge_label==0] \n",
    "                           for d in val_list], dim=1)\n",
    "    neg_test1 = torch.cat([d.edge_label_index[:, d.edge_label==0] \n",
    "                            for d in test_list], dim=1)\n",
    "    neg_train2 = train_data3.edge_label_index[:, train_data3.edge_label==0]             \n",
    "    neg_val2 = val_data3.edge_label_index[:, val_data3.edge_label==0] \n",
    "    neg_test2 = test_data3.edge_label_index[:, test_data3.edge_label==0]\n",
    "    neg_train = torch.cat([neg_train1, neg_train2], dim=1)\n",
    "    neg_val = torch.cat([neg_val1, neg_val2], dim=1)\n",
    "    neg_test = torch.cat([neg_test1, neg_test2], dim=1)\n",
    "    train_data = Data(\n",
    "        edge_index=train_data3.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        edge_label_index=torch.cat([pos_train, neg_train], dim=1),\n",
    "        edge_label=torch.cat([\n",
    "            torch.ones(pos_train.size(1), dtype=torch.long),\n",
    "            torch.zeros(neg_train.size(1), dtype=torch.long)\n",
    "        ])\n",
    "    )\n",
    "    val_data = Data(\n",
    "        edge_index=val_data3.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        edge_label_index=torch.cat([pos_val, neg_val], dim=1),\n",
    "        edge_label=torch.cat([\n",
    "            torch.ones(pos_val.size(1), dtype=torch.long),\n",
    "            torch.zeros(neg_val.size(1), dtype=torch.long)\n",
    "        ])\n",
    "    )\n",
    "    test_data = Data(\n",
    "        edge_index=test_data3.edge_index,\n",
    "        num_nodes=data.num_nodes,\n",
    "        edge_label_index=torch.cat([pos_test, neg_test], dim=1),\n",
    "        edge_label=torch.cat([\n",
    "            torch.ones(pos_test.size(1), dtype=torch.long),\n",
    "            torch.zeros(neg_test.size(1), dtype=torch.long)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    print(train_data)\n",
    "    print(val_data)\n",
    "    print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ae9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.x = torch.ones((train_data.num_nodes, 1))\n",
    "val_data.x = train_data.x.clone()\n",
    "test_data.x = train_data.x.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce8078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(\n",
    "    in_channels=1,\n",
    "    hidden_channels = 64,\n",
    "    num_layers = 2,\n",
    "    aggr = \"lstm\"\n",
    ")\n",
    "\n",
    "\n",
    "def predictor(z, edge_label_index):\n",
    "    edge_emb_src = z[edge_label_index[0]]\n",
    "    edge_emb_dst = z[edge_label_index[1]]\n",
    "    edge_emb_src = F.normalize(edge_emb_src, dim = -1)\n",
    "    edge_emb_dst = F.normalize(edge_emb_dst, dim = -1)\n",
    "    pred = (edge_emb_src * edge_emb_dst).sum(dim = -1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbb7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = LinkNeighborLoader(\n",
    "    data = train_data,\n",
    "    num_neighbors = [25, 10],\n",
    "    edge_label_index = train_data.edge_label_index,\n",
    "    edge_label = train_data.edge_label,\n",
    "    batch_size = 128,\n",
    "    shuffle = True\n",
    ")\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data = val_data,\n",
    "    num_neighbors = [25, 10], \n",
    "    edge_label_index = val_data.edge_label_index,\n",
    "    edge_label = val_data.edge_label,\n",
    "    batch_size = 128,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cc6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model(batch.x, batch.edge_index)\n",
    "        pred = predictor(z, batch.edge_label_index)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, batch.edge_label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss = total_loss + loss.item()\n",
    "        count = count + 1\n",
    "    return total_loss / count\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    y_truth = []\n",
    "    y_pred = []\n",
    "    for batch in val_loader:\n",
    "        z = model(batch.x, batch.edge_index)\n",
    "        pred = predictor(z, batch.edge_label_index)\n",
    "        y_truth.append(batch.edge_label)\n",
    "        y_pred.append(torch.sigmoid(pred))\n",
    "    y_truth = torch.cat(y_truth).numpy()\n",
    "    y_pred = torch.cat(y_pred).detach().numpy()\n",
    "    auc = roc_auc_score(y_truth, y_pred)\n",
    "    ap = average_precision_score(y_truth, y_pred)\n",
    "    return auc, ap\n",
    "    \n",
    "#ROC-AUC : la probabilité qu’un positif ait un score plus haut qu’un négatif\n",
    "#AP : aproxime l'air sous la courbe Precisoion/Recall, plus les positifs sont rares plus un bon score AP est difficile à obtenir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52885357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Loss: 0.6313, Val AUC: 0.8624, Val AP: 0.8480\n",
      "Epoch 002, Loss: 0.5347, Val AUC: 0.8676, Val AP: 0.8500\n",
      "Epoch 003, Loss: 0.5300, Val AUC: 0.8330, Val AP: 0.8275\n",
      "Epoch 004, Loss: 0.5286, Val AUC: 0.8690, Val AP: 0.8736\n",
      "Epoch 005, Loss: 0.5275, Val AUC: 0.8412, Val AP: 0.8654\n",
      "Epoch 006, Loss: 0.5280, Val AUC: 0.8553, Val AP: 0.8720\n",
      "Epoch 007, Loss: 0.5265, Val AUC: 0.8656, Val AP: 0.8741\n",
      "Epoch 008, Loss: 0.5270, Val AUC: 0.8584, Val AP: 0.8709\n",
      "Epoch 009, Loss: 0.5257, Val AUC: 0.8613, Val AP: 0.8740\n",
      "Epoch 010, Loss: 0.5252, Val AUC: 0.8562, Val AP: 0.8668\n",
      "Early stop\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = 0\n",
    "limit = 6\n",
    "count = 0\n",
    "train_losses = []\n",
    "val_aps = []\n",
    "val_aucs = []\n",
    "for epoch in range(1, 50):\n",
    "    loss = train_epoch()\n",
    "    train_losses.append(loss)\n",
    "    val_auc, val_ap = evaluate()\n",
    "    val_aps.append(val_ap)\n",
    "    val_aucs.append(val_auc)\n",
    "    print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Val AUC: {val_auc:.4f}, Val AP: {val_ap:.4f}\")\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        count = 0\n",
    "    else:\n",
    "        count =  count + 1\n",
    "        if count >= limit:\n",
    "            print(\"Early stop\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
